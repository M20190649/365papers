---
layout: post
title: "Learning a neural response metric for retinal prosthesis"
byline: Shah et al
doi: "10.1101/226530"
tags:
    - retina
    - vision
    - prostheses
    - neuroscience
    - RGC
    - CNN
    - neural-network
summary: Using neural networks, it is possible to "learn" the optimal signals to send with a retinal prosthesis to most closely emulate the signals sent by the healthy retinal cells.
---

Most state-of-the-art retinal prostheses send a signal, via the optic nerve, to visual cortex in an emulation of a healthy retina. However, the signals sent by _healthy_ retina is difficult to copy: The signal is nuanced and complex, and every eye may be different.

So it's important that the retinal prosthesis sends a signal along the "wire" that looks as close as possible to the endogenous stimulus as possible.

This team proposes a method for determining a similarity measure of endogenous retinal signals with artificial, electrical signals sent by the prosthesis. Using monkey retina, the researchers first produce a visual stimulus and record the native signal sent by RGCs, and then "learn" the correct way to represent this response using the prosthesis. Because the hardware of the prosthesis is limited, the researchers found that a CNN was the best way to learn the right configuration to represent visual signals using the artificial channels.

I wish I could give this paper a deeper dive but today's another busy day at re:invent. So... Perhaps more on this later.
