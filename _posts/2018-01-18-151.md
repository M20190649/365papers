---
layout: post
title: "Reinforcement Learning based Recommender System using Biclustering Technique"
byline: Choi et al
arxiv: "1801.05532"
tags:
    - reinforcement-learning
    - recommender
    - biclustering
    - explainability
summary: This recommender engine uses reinforcement learning to generate high-quality item recommendations for a purchasing user "buyer" agent.
---

This paper reviews a new type of recommender system — a system designed to use prior knowledge to recommend likely new relationships — that uses a "_biclustering technique_" to reduce the sample space of the algorithm, even enabling a "cold start" from a condition with no prior knowledge about user preferences.

The biclustering approach addresses both items — a target — and buyers — the users — as independent sets that can be independently or collectively analysed. Existing systems like _collaborative filtering_ rely on large amounts of users or large numbers of purchases per user, and often fail in cases where there are not that many purchases per user.

In short, both users as well as items are embedded in a state-space into which a reinforcement-learning system can sample, optimizing that embedding for the most accurate recommendations. The algorithm, the authors explain, is even _explainable_, because the reason for the choice can be correlated with similar users or similar purchases.

My understanding of this algorithm is that it still performs with roughly the same time-complexity as more conventional approaches, which means that it is a viable drop-in for commercial applications or other large-scale systems that already have a recommendation engine in use.
