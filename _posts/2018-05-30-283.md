---
layout: post
title: "Deep Reinforcement Learning in Ice Hockey for Context-Aware Player Evaluation"
byline: "Liu & Schulte"
arxiv: "1805.11088"
tags:
    - deep-learning
    - machine-learning
    - neural-network
    - LSTM
    - Canada
    - hockey
    - evaluation
    - performance
    - prediction
    - behavior
    - Markov
    - reinforcement-learning
summary: This deep learning approach evaluates hockey players based upon their total impact on the outcome of a game.
---

This is an extremely Canada paper.

Liu and Schulte developed a deep reinforcement learning net that learned to gauge a hockey player's performance and their influence upon the outcome of a game: This _Game Impact Metric_ (GIM) correlates well with future career success, and remains relatively stable during a single game, which suggests that it's both a useful metric for assessing a player as well as a relatively reliable metric at a point in time during a game.

In order to create their model, _all_ of a player's actions (based upon the three million actions coded in the _SPORTLOGiQ_ dataset) were encoded as an input to the network (in contrast with some previous approaches which only used actions when a player was in possession of the puck, or limited to actions that directly resulted in a goal). From this, a $Q$ function is "learned" to predict the probability that, given the current event and the ones that led up to it, the current team scores the next goal. (Understandably,previous approaches have used a Markov model to represent this relationship.)

This function can be used to estimate the value of individual actions, which can be assigned to a particular player in order to predict the value of an individual to the outcome of the game or season.
GIM correlates well — but not perfectly — with salary or total contract amount.
