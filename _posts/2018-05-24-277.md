---
layout: post
title: "The Roles of Supervised Machine Learning in Systems Neuroscience"
byline: Glaser, Benjamin, Farhoodi & Kording
arxiv: "1805.08239"
tags:
    - neuroscience
    - machine-learning
    - neural-network
    - random-forest
    - brain
    - architecture
    - spiking-neural-network
    - model
    - systems-neuroscience
    - supervised-learning
summary: Machine learning has become an irreplaceable tool in the neuroscientist's toolbox for a number of distinct but co-emergent reasons.
---

Some huge number of the papers I've read so far for this project have involved — in some form or another — both neuroscience and machine learning in conjunction with one another. Sometimes that is in the form of computer vision for image segmentation; sometimes it's in the form of using neuroscientific discoveries of the past in order to design more robust, more biofidelic, or more interesting artificial neural networks. And a few have even discussed how artificial neural networks _suck_ compared to the biological counterparts.

This preprint looks specifically at how machine learning has influenced (and will continue to influence) neuroscience — effectively, the opposite direction of information flow compared to the conventional notion of designing biofidelic systems.

The authors classify these influences into four main categories:

**Solutions to engineering challenges.** Neuroscience research raises many complex questions regarding the relationships between input "knowns" and output predictions. ML assists — intuitively enough — in this sort of classic challenge of understanding input/output correlation.

**Predictive variables.** This is the evaluation of a large set of inputs, in pursuit of learning which correlate most closely wth a known output. The most clear-cut example of this is passing arbitrary neurological data to a ML algo in order to attempt to predict or diagnose disease.

**Setting benchmarks for simple models.** Machine learning techniques are very well-suited to the problem of distinguishing between how much of a model's failure is attributable to shortcomings in the model and how much is attributable to noisy input data or low-fidelity signal.

**Acting as a model of the brain.**  Computational models — artificial neural networks — are quite different from the endogenous, spiking neurons of the brain. But the two systems have similarities as well: Tuning curves appear to be a fundamental component of distributed-computing systems that follow the simple node-edge architecture. This will only shed more light on the brain as spiking neural network models grow in popularity and efficiency.
