---
layout: post
title: "“Like Sheep Among Wolves”: Characterizing Hateful Users on Twitter"
byline: Ribiero et al
arxiv: "1801.00317"
tags:
    - social-networks
    - twitter
    - hate-speech
    - graphs
    - sentiment-analysis
    - graph-theory
    - botnet
summary: Hateful users can be identified by several interesting characteristics, including account-creation, followership ratios, and retweet networks.
---

Anyone who has spent any time at all on Twitter knows that hate speech, racism, and overall Badness are pretty rampant on the platform. Tracking these users can often be pretty simple: Just put some racist slur into the searchbar and you're guaranteed to have more garbagetwitter than you can handle.

But identifying users that are _hateful_, rather than simply using such words, can be trickier. (For example, quoting Trump doesn't mean you're a racist shithead too.) How do you identify the sentiment behind the text?

The authors of this paper crowdsourced the hand-annotation of nearly 5000 tweets, classifying them as "hateful" or "not hateful", and then compared these human-generated results with the results of their automatic graph analysis.

Some results: Hateful users (users whose tweets were more commonly hand-annotated as "hateful") often have more recent account-creation dates; they often have greater numbers of new followers per day since account creation (another indication of bots), and they favorite more tweets.

Though the authors note that they found no indications that these users were bots, I would be very interested in further investigation: All of the points mentioned above are highly consistent with bot networks, which I've written about before ([#46](http://blog.jordan.matelsky.com/365papers/46/)).

Apropos of nothing, first-author Manoel Horta Ribeiro is [on Twitter](https://twitter.com/manoelribeiro), if you'd like to say hi.
