---
layout: post
title: "Equation-oriented specification of neural models for simulations"
byline: Stimberg et al
doi: "10.3389/fninf.2014.00006"
tags:
    - neuroscience
    - simulation
    - neural-network
    - model
    - neural-models
    - spiking-neural-network
    - python
summary: Brian2 uses membrane potential equation-based models in order to simulate biological spiking neural networks through Python.
---

Though this paper is a bit older — it's from 2014 — it discusses neural simulation on computer architecture, which is a field that is not only gaining in popularity now (vis-a-vis neuromorphic computing) but is also really, _really_ cool.

The authors propose a mathematical, equation-based system for assigning complex behavior to neural models, and implement this specification in [the _Brian2_ simulator framework](http://briansimulator.org/).

Brian2, which has seen [plenty of recent development](https://github.com/brian-team/brian2/), is a powerful, open-source spiking neural network simulator based upon a clock-driven event cycle.

The premise of this specification is that neuronal membrane potentials follow complex formulae and modeling real neurons — even with the best science available today — is still very difficult. State of the art neuron models still deviate pretty severely from the real thing.

So how do you build a simulator that can grow as the field learns more about neurons? Let the user define the model equations.

As neuroscientists learn more about neurons, they can improve the equations that are fed into the model. When researchers want a faster and rougher approximation instead, they can dial the complexity back down and generate results based upon simpler models, like the famous _Leaky Integrate and Fire_ model, or the _Hodgkin-Huxley_ model.

I've played a bit with Brian and it's a very exciting platform for a variety of reasons; but my favorite aspect of it is how accessible the code is to a newcomer. (Much like the rational behind PyTorch, the developers decided it was worth sacrificing some performance in the pursuit of readability and intuition.)
