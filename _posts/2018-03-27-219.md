---
layout: post
title: "The connection-set algebra â€” a novel formalism for the representation of connectivity structure in neuronal network models."
byline: Mikael Djurfeldt
doi: "10.1007/s12021-012-9146-1"
tags:
    - neuroscience
    - neural-network
    - neuronal-network
    - grammar
    - algebra
    - model
    - simulation
    - neurons
    - matrix
    - connection-set
summary: A formalized grammar enables us to speak about biological neuronal network approximations with mathematical rigor.
---

In this work, Mikael Djurfeldt puts forward a common language for conveying the connectivity patterns of neurons in a _neuronal network_, a terminology that I like a lot for describing neural networks in a biological setting (versus a computer science one), but which I think didn't really catch on except in the community that actively discusses both neurons and machine learning on a daily basis WHICH OUGHT TO BE EVERYONE but I digress

The adjacency matrix is a common notation for directed graph connectivity: If node $i$ has an edge to node $j$, then $M(i, j) = \mathcal{T}$. Otherwise, $M(i, j) = \mathcal{F}$, where $\mathcal{T}$ and $\mathcal{F}$ are the boolean "true" and "false" values, or, in matrix-talk, integers 1 and 0.

This is obviously extensible to neuronal connectivity: If neuron $i$ transmits data to neuron $j$...

Djurfeldt proposes a formal algebra for dealing with neuronal networks, which uses a few matrix primitives to express complex concepts succinctly and consistently.

For example, here is a network where every neuron is connected to every other neuron _except_ itself:

$$\bar{\Omega} - \bar{\delta}$$

A neuronal network where every neuron connects to its peers with a probability dependent on their distance could be represented as:

$$(\rho\mathcal{D})(i, j) = X_{ij}$$

...where $\mathcal{D}$ is some distribution.

Though this is still a very simple formulation, we can now begin to play with the mathematic truths that arise from these definitions. For example, we can set:

$$\bar{\delta} = \mathcal{D} \textit{ where } \mathcal{D} = \{^{\mathcal{T} \text{ if distance is 0}}_{\mathcal{F} \text{ otherwise}}$$

Now these formulas are interchangeable and anything that we learn about a probablistic connectivity set we can now apply to our Diagonal pattern.

This feels like a very useful grammar to define, because we can use it to learn about connection sets in neuronal networks that are too large to simulate explicitly. I can see this sort of mathematical reduction being useful for reducing complex networks to tractable ones: Djurfeldt explains that this can even be used to partition a network into subpopulations that can be separately simulated in parallel on different (compute) nodes.
