---
layout: post
title: "Creating a Social Brain for Cooperative Connected Autonomous Vehicles: Issues and Challenges"
byline: Seng W. Loke
arxiv: "1710.00461"
tags:
    - autonomy
    - self-driving-cars
    - artificial-intelligence
summary: A common language for autonomous vehicles can improve collaboration and information-sharing across a network fabric.
---

Loke proposes rules for autonomous vehicles in this paper, and subdivides the rules for communication into vehicle-to-vehicle (cars talking to cars), vehicle-to-thing (cars talking to wheelchairs, stop signs, etc) and vehicle-to-pedestrian (visible or audible signals that are human-readable).

This paper explains a variety of modalities in which these communication techniques can be standardized, including:

**Assertives.** These are factual statements about how the vehicle senses the world.

**Directives.** These are requests for other actors in the world to take action; for example, a first-aid vehicle might request others move aside.

**Commissives.** These are promises that a vehicle makes, the failure to do which can be punished in a "social" autonomous-vehicle brain.

**Espressives.** This includes things like "thanks!" or "sorry!" to other vehicles or pedestrians.

**Declarations.** A vehicle can declare states about the world around it ("this lane is no longer closed") to inform peers.

This combination of communication channels enables cars to transmit important information to its peers, including driving rules, regional driving conventions, and information about the environment ("be careful of this pothole").

By normalizing _a_ language (whether it is this one or not), we will enable autonomous vehicles to communicate in a "collaboration layer" that runs on top of the network layer of IoT, autonomous vehicles, and stationary or aerial traffic direction agents.
