---
layout: post
title: "Deep Learning for Isotropic Super-Resolution from Non-isotropic 3D Electron Microscopy"
byline: "Heinrich, Bogovic & Saalfeld"
doi: "10.1007/978-3-319-66185-8_16"
tags:
    - anisotropy
    - electron-microscopy
    - EM
    - deep-learning
    - CNN
    - U-net
    - super-resolution
    - neural-network
    - "group:janelia"
summary: Two deep-learning approaches recover missing data along the low-resolution axis of anisotropic 3D electron microscopy datasets.
---

Anisotropy — the fact that the $x$ and $y$ dimensions are sampled at a higher resolution than the $z$ dimension — is a huge pain-point in electron microscopy.

Some EM imaging techniques (such as ssTEM or sbSEM) avoid this problem altogether, but the fact remains that large anisotropic datasets exist and more will continue to be collected for the forseeable future.

Heinrich et al propose here a way of "hallucinating" the missing $z$-dimension data by training novel U-nets or 3D-FSRCNNs (originally used for super-resolution of 2D images) on isotropic FIB-SEM data.

The best 3D-FSRCNN network took less than half as long to train as the best 3D-SRU-Net, but the _worst_ U-net still outperformed the best 3D-FSRCNN (and took less time to train).

The results of this paper are pretty stunning: The 3D-SRU-Net results manage to capture tiny structures that are entirely lost in the downsampling process. This suggests that the U-nets are a good stand-in for replacing the missing data in anisotropic EM techniques; in fact, it may even mean that lower-resolution data could be collected along _all_ axes without too many negative effects.
