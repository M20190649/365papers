---
layout: post
title: "Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields"
byline: Unterthiner et al
arxiv: "1708.08819"
tags:
    - neural-network
    - Nash-equilibrium
    - game-theory
    - celebA
    - optimization
    - force
    - training
    - physics
    - interaction
    - mode-collapse
    - electricity
    - GAN
    - machine-learning
summary: Modeling a GAN target distribution as an electric field removes all but one single Nash equilibrium, improving training efficacy and output quality.
---

Though GANs are generally very good at from-scratch image synthesis, they often sink into local maxima in their journey to most closely model a target distribution. This is, of course, a bad thing: If a GAN gets stuck optimizing on a local maximum, it's unlikely to ever generate truly useful or representative images.

This is particularly noticeable in cases of mode-collapse (where the generator network samples only from a very small portion of the distribution, and thus generates only sets of of very similar images). Modeling this as a game-theory challenge, mode collapse is when the GAN encounters any of many suboptimal Nash equilibria from which it is penalized for moving.

To mitigate this, the authors propose a new training scheme for GANs which has only one Nash equilibrium. This means that the GAN is _proven_ to have only one optimal convergence, and the generator will not be rewarded in local cases of mode collapse.

The Coloumb GAN achieves this by modeling the target and model distributions as charged particles interacting in a potential field. Potential fields are a convenient model for optimization problems [[#6](http://blog.jordan.matelsky.com/365papers/6)] [[#344](http://blog.jordan.matelsky.com/365papers/344)] because they serve as a self-organizing yet simple and deterministic mechanic. In a Coloumb GAN, positively charged "true samples" (those from the training set) attract generated samples (those created by the generator net), but negatively charged generated samples repel each other. By rewarding the generator for adequately distancing new samples from existing samples (minimizing the electric potential), the GAN trends toward a more diverse generated output set, more accurately and comprehensively capturing the target training input.
